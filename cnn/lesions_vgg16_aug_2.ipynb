{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesions_vgg16-aug_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SmUmmSr6RF9",
        "outputId": "894659f9-7a87-4d53-8467-3f96f86b6dd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 24 13:50:12 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    26W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrDSYQ0jhn0A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import keras\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from sys import getsizeof\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import f1_score\n",
        "from skimage.transform import rescale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "HzCcCp9moaF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_path = '/content/drive/MyDrive/Newcastle University/Machine Learning/lesions'"
      ],
      "metadata": {
        "id": "IOMk8f_dmKwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_paths(path):\n",
        "  \n",
        "  image_paths = []\n",
        "  y = []\n",
        "  \n",
        "  for label, elem in enumerate(os.listdir(path)):\n",
        "\n",
        "    print('class: ' + elem + ' | label: ' + str(label))\n",
        "    path1 = path + '/' + elem\n",
        "    images = os.listdir(path1)\n",
        "    for im in images:\n",
        "      image_paths.append(path1 + '/' + im)\n",
        "      y.append(str(label))\n",
        "  \n",
        "  # shuffle\n",
        "  c = list(zip(image_paths,y))\n",
        "  np.random.shuffle(c)\n",
        "  image_paths,y = zip(*c)\n",
        "  \n",
        "  return image_paths, keras.utils.to_categorical(y, num_classes=7)\n",
        "\n",
        "image_paths, labels = load_paths(data_path)"
      ],
      "metadata": {
        "id": "M_-pKhKXxIXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(image_paths, labels, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "RslIdZEqxIap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data (non-augmented)\n",
        "train_path1 = '/content/drive/MyDrive/NCL/ML/Dataset/train'\n",
        "# Training data (augmented)\n",
        "train_path2 = '/content/drive/MyDrive/NCL/ML/Dataset/output'\n",
        "# Testing data\n",
        "valid_path = '/content/drive/MyDrive/NCL/ML/Dataset/validation'"
      ],
      "metadata": {
        "id": "AFCQOVwsqPFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(os.listdir(train_path2))"
      ],
      "metadata": {
        "id": "Lkn46_DxLmhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = []\n",
        "train_labels = []\n",
        "\n",
        "#elem_list1 = os.listdir(path_train)\n",
        "\n",
        "for label, elem in enumerate(classes):\n",
        "  \n",
        "  path1 = train_path2 + '/' + str(elem)\n",
        "  images = os.listdir(path1)\n",
        "  \n",
        "  for im in images:\n",
        "      \n",
        "      # takes the whole path of the images\n",
        "      # removes the need to mention the dataset path for the generator\n",
        "      train_list.append(path1 + '/' + str(im))\n",
        "      train_labels.append(label)\n",
        "\n",
        "# shuffling the image list\n",
        "c = list(zip(train_list, train_labels))\n",
        "np.random.shuffle(c)\n",
        "train_list, train_labels = zip(*c)\n",
        "\n",
        "# one hot encoding\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes=7)"
      ],
      "metadata": {
        "id": "ilEC-AuZLomZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = []\n",
        "test_labels = []\n",
        "\n",
        "#elem_list1 = os.listdir(path_train)\n",
        "\n",
        "for label, elem in enumerate(classes):\n",
        "  \n",
        "  path1 = valid_path + '/' + str(elem)\n",
        "  images = os.listdir(path1)\n",
        "  \n",
        "  for im in images:\n",
        "      \n",
        "      # takes the whole path of the images\n",
        "      # removes the need to mention the dataset path for the generator\n",
        "      test_list.append(path1 + '/' + str(im))\n",
        "      test_labels.append(label)\n",
        "\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes=7)"
      ],
      "metadata": {
        "id": "7R2woQJ5MBEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX_Npcuere-o",
        "outputId": "1616670d-4cb8-45a7-be2c-8838c4c4d11e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-vDMM_OrKI6",
        "outputId": "63f2dd59-cc30-4a36-e367-ecacd126b646"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2005, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator for data loading while training the model\n",
        "def im_datagen(image_list, label_list, batch_size = 32, shuffle = False):\n",
        "    while True:\n",
        "        # shuffle the data\n",
        "        if shuffle == True:\n",
        "            c = list(zip(image_list, label_list))\n",
        "            np.random.shuffle(c)\n",
        "            image_list, label_list = zip(*c)\n",
        "    \n",
        "        total_elements = len(label_list)\n",
        "    \n",
        "        for i in range(0, total_elements, batch_size):\n",
        "          \n",
        "          images = [cv2.resize(cv2.imread(x), (224,224)) for x in image_list[i:i+batch_size]]\n",
        "          images = np.asarray(images)\n",
        "          images = images/255.\n",
        "          \n",
        "          yield images, keras.utils.to_categorical(label_list[i:i+batch_size], num_classes = 7)"
      ],
      "metadata": {
        "id": "r71nYx7-Lopc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size = 50"
      ],
      "metadata": {
        "id": "v9HScY7I3932"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP_SIZE_TRAIN = len(train_labels)//batch_size\n",
        "STEP_SIZE_VALID = len(test_labels)//batch_size\n",
        "\n",
        "print(STEP_SIZE_TRAIN)\n",
        "print(STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "8cmqcVB3cY6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_gen = im_datagen(train_list, train_labels, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_gen = im_datagen(test_list, test_labels, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "mxMglYp_dZas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_test.[17]"
      ],
      "metadata": {
        "id": "DnBt86wk4t3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_test[17]"
      ],
      "metadata": {
        "id": "yxN19TlH8P4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter(y_test).keys() # equals to list(set(words))"
      ],
      "metadata": {
        "id": "COF20gK3xIeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter(y_test).values() # counts the elements' frequency"
      ],
      "metadata": {
        "id": "antHWObT3nF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeisonSequence(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size = 32):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "        images = []\n",
        "\n",
        "        for file_name in batch_x:\n",
        "          images.append(cv2.resize(cv2.imread(file_name), (224, 224)))\n",
        "\n",
        "        return (np.array(images)/255), np.array(batch_y)"
      ],
      "metadata": {
        "id": "qLIkj9LCxIhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "test = []\n",
        "\n",
        "for file_name in x_test[0:5]:\n",
        "  test.append(rescale(io.imread(file_name), (0.5, 0.5, 1)))\n",
        "  #print(file_name)\n",
        "\n",
        "test = np.array(test)\n",
        "plt.imshow(test[3])"
      ],
      "metadata": {
        "id": "AWR3pGgIfO_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_gen = LeisonSequence(train_list, train_labels, 100)\n",
        "val_img_gen = LeisonSequence(test_list, test_labels, 50)"
      ],
      "metadata": {
        "id": "x-EVrrT2xIl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model = keras.applications.ResNet50(\n",
        "model = keras.applications.VGG16(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    classes=7,\n",
        "    pooling=None\n",
        ")"
      ],
      "metadata": {
        "id": "o18kmISZ5Zfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model.summary()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aYNxMbg6RJD",
        "outputId": "94b938e2-1b2d-4d10-8837-e9e7cd5080b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " fc1 (Dense)                 (None, 4096)              102764544 \n",
            "                                                                 \n",
            " fc2 (Dense)                 (None, 4096)              16781312  \n",
            "                                                                 \n",
            " predictions (Dense)         (None, 7)                 28679     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 134,289,223\n",
            "Trainable params: 134,289,223\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "last_layer = base_model.get_layer('global_average_pooling2d')\n",
        "\n",
        "print ('last layer output shape:', last_layer.output_shape)\n",
        "\n",
        "bm_out = last_layer.output\n",
        "#x = base_model(inputs, training=False)\n",
        "x = keras.layers.Dense(128, activation='relu')(bm_out)\n",
        "#x = keras.layers.Dropout(0.5)(x)\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\n",
        "#model = keras.Model(inputs, outputs)\n",
        "model = keras.Model(base_model.input, outputs)"
      ],
      "metadata": {
        "id": "drtS5_zLyPjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UvClYg6czAlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0002,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.9)\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.0002)\n",
        "adam = keras.optimizers.Adam(learning_rate=lr_schedule, amsgrad=True)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.0002)"
      ],
      "metadata": {
        "id": "x8q9amiXYVZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=sgd ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KDeUMEV66RMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/NCL/ML/Models/vgg16_aug.h5')"
      ],
      "metadata": {
        "id": "yVvfUzC8x35n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = keras.callbacks.ModelCheckpoint(filepath = '/content/drive/MyDrive/NCL/ML/Models/vgg16_aug_2.h5', verbose = 1, save_best_only = True, monitor='val_accuracy')"
      ],
      "metadata": {
        "id": "XFcQU2BP6RPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_img_gen, epochs=50, validation_data=val_img_gen, callbacks=cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b8WWMNB6RR_",
        "outputId": "abe9a8e6-248b-472d-dd12-4d3cfb914c3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4567 - accuracy: 0.8277 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.75362, saving model to /content/drive/MyDrive/NCL/ML/Models/vgg16_aug_2.h5\n",
            "200/200 [==============================] - 6408s 32s/step - loss: 0.4567 - accuracy: 0.8277 - val_loss: 0.6877 - val_accuracy: 0.7536\n",
            "Epoch 2/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4401 - accuracy: 0.8340\n",
            "Epoch 00002: val_accuracy improved from 0.75362 to 0.76010, saving model to /content/drive/MyDrive/NCL/ML/Models/vgg16_aug_2.h5\n",
            "200/200 [==============================] - 561s 3s/step - loss: 0.4401 - accuracy: 0.8340 - val_loss: 0.7132 - val_accuracy: 0.7601\n",
            "Epoch 3/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4324 - accuracy: 0.8356\n",
            "Epoch 00003: val_accuracy did not improve from 0.76010\n",
            "200/200 [==============================] - 557s 3s/step - loss: 0.4324 - accuracy: 0.8356 - val_loss: 0.6997 - val_accuracy: 0.7581\n",
            "Epoch 4/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4288 - accuracy: 0.8375\n",
            "Epoch 00004: val_accuracy improved from 0.76010 to 0.76060, saving model to /content/drive/MyDrive/NCL/ML/Models/vgg16_aug_2.h5\n",
            "200/200 [==============================] - 562s 3s/step - loss: 0.4288 - accuracy: 0.8375 - val_loss: 0.6966 - val_accuracy: 0.7606\n",
            "Epoch 5/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4255 - accuracy: 0.8389\n",
            "Epoch 00005: val_accuracy did not improve from 0.76060\n",
            "200/200 [==============================] - 558s 3s/step - loss: 0.4255 - accuracy: 0.8389 - val_loss: 0.7097 - val_accuracy: 0.7546\n",
            "Epoch 6/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4184 - accuracy: 0.8424\n",
            "Epoch 00006: val_accuracy improved from 0.76060 to 0.76259, saving model to /content/drive/MyDrive/NCL/ML/Models/vgg16_aug_2.h5\n",
            "200/200 [==============================] - 561s 3s/step - loss: 0.4184 - accuracy: 0.8424 - val_loss: 0.7138 - val_accuracy: 0.7626\n",
            "Epoch 7/50\n",
            "200/200 [==============================] - ETA: 0s - loss: 0.4142 - accuracy: 0.8432\n",
            "Epoch 00007: val_accuracy did not improve from 0.76259\n",
            "200/200 [==============================] - 557s 3s/step - loss: 0.4142 - accuracy: 0.8432 - val_loss: 0.7300 - val_accuracy: 0.7626\n",
            "Epoch 8/50\n",
            "132/200 [==================>...........] - ETA: 2:56 - loss: 0.4199 - accuracy: 0.8403"
          ]
        }
      ]
    }
  ]
}