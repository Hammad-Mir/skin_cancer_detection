{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lesions_ResNet50_aug.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SmUmmSr6RF9",
        "outputId": "a62f01ce-fbec-481f-c2f6-11cb743c2268"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan 24 01:56:03 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   44C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zrDSYQ0jhn0A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import math\n",
        "import keras\n",
        "import numpy as np\n",
        "from skimage import io\n",
        "from sys import getsizeof\n",
        "from tensorflow import keras\n",
        "from sklearn.metrics import f1_score\n",
        "from skimage.transform import rescale\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "metadata": {
        "id": "HzCcCp9moaF7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "data_path = '/content/drive/MyDrive/Newcastle University/Machine Learning/lesions'"
      ],
      "metadata": {
        "id": "IOMk8f_dmKwd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "def load_paths(path):\n",
        "  \n",
        "  image_paths = []\n",
        "  y = []\n",
        "  \n",
        "  for label, elem in enumerate(os.listdir(path)):\n",
        "\n",
        "    print('class: ' + elem + ' | label: ' + str(label))\n",
        "    path1 = path + '/' + elem\n",
        "    images = os.listdir(path1)\n",
        "    for im in images:\n",
        "      image_paths.append(path1 + '/' + im)\n",
        "      y.append(str(label))\n",
        "  \n",
        "  # shuffle\n",
        "  c = list(zip(image_paths,y))\n",
        "  np.random.shuffle(c)\n",
        "  image_paths,y = zip(*c)\n",
        "  \n",
        "  return image_paths, keras.utils.to_categorical(y, num_classes=7)\n",
        "\n",
        "image_paths, labels = load_paths(data_path)"
      ],
      "metadata": {
        "id": "M_-pKhKXxIXc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(image_paths, labels, test_size = 0.2, random_state = 42)"
      ],
      "metadata": {
        "id": "RslIdZEqxIap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training data (non-augmented)\n",
        "train_path1 = '/content/drive/MyDrive/Newcastle University/Machine Learning/Dataset/train'\n",
        "# Training data (augmented)\n",
        "train_path2 = '/content/drive/MyDrive/Newcastle University/Machine Learning/Dataset/output'\n",
        "# Testing data\n",
        "valid_path = '/content/drive/MyDrive/Newcastle University/Machine Learning/Dataset/validation'"
      ],
      "metadata": {
        "id": "AFCQOVwsqPFp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = sorted(os.listdir(train_path2))"
      ],
      "metadata": {
        "id": "Lkn46_DxLmhw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = []\n",
        "train_labels = []\n",
        "\n",
        "#elem_list1 = os.listdir(path_train)\n",
        "\n",
        "for label, elem in enumerate(classes):\n",
        "  \n",
        "  path1 = train_path2 + '/' + str(elem)\n",
        "  images = os.listdir(path1)\n",
        "  \n",
        "  for im in images:\n",
        "      \n",
        "      # takes the whole path of the images\n",
        "      # removes the need to mention the dataset path for the generator\n",
        "      train_list.append(path1 + '/' + str(im))\n",
        "      train_labels.append(label)\n",
        "\n",
        "# shuffling the image list\n",
        "c = list(zip(train_list, train_labels))\n",
        "np.random.shuffle(c)\n",
        "train_list, train_labels = zip(*c)\n",
        "\n",
        "# one hot encoding\n",
        "train_labels = keras.utils.to_categorical(train_labels, num_classes=7)"
      ],
      "metadata": {
        "id": "ilEC-AuZLomZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_list = []\n",
        "test_labels = []\n",
        "\n",
        "#elem_list1 = os.listdir(path_train)\n",
        "\n",
        "for label, elem in enumerate(classes):\n",
        "  \n",
        "  path1 = valid_path + '/' + str(elem)\n",
        "  images = os.listdir(path1)\n",
        "  \n",
        "  for im in images:\n",
        "      \n",
        "      # takes the whole path of the images\n",
        "      # removes the need to mention the dataset path for the generator\n",
        "      test_list.append(path1 + '/' + str(im))\n",
        "      test_labels.append(label)\n",
        "\n",
        "test_labels = keras.utils.to_categorical(test_labels, num_classes=7)"
      ],
      "metadata": {
        "id": "7R2woQJ5MBEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rX_Npcuere-o",
        "outputId": "f353caaf-ae23-4021-c5a0-d9c46611dcc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_labels.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-vDMM_OrKI6",
        "outputId": "8388cbe3-56af-4186-f0aa-4877708f7026"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2005, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generator for data loading while training the model\n",
        "def im_datagen(image_list, label_list, batch_size = 32, shuffle = False):\n",
        "    while True:\n",
        "        # shuffle the data\n",
        "        if shuffle == True:\n",
        "            c = list(zip(image_list, label_list))\n",
        "            np.random.shuffle(c)\n",
        "            image_list, label_list = zip(*c)\n",
        "    \n",
        "        total_elements = len(label_list)\n",
        "    \n",
        "        for i in range(0, total_elements, batch_size):\n",
        "          \n",
        "          images = [cv2.resize(cv2.imread(x), (224,224)) for x in image_list[i:i+batch_size]]\n",
        "          images = np.asarray(images)\n",
        "          images = images/255.\n",
        "          \n",
        "          yield images, keras.utils.to_categorical(label_list[i:i+batch_size], num_classes = 7)"
      ],
      "metadata": {
        "id": "r71nYx7-Lopc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size = 50"
      ],
      "metadata": {
        "id": "v9HScY7I3932"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "STEP_SIZE_TRAIN = len(train_labels)//batch_size\n",
        "STEP_SIZE_VALID = len(test_labels)//batch_size\n",
        "\n",
        "print(STEP_SIZE_TRAIN)\n",
        "print(STEP_SIZE_VALID)"
      ],
      "metadata": {
        "id": "8cmqcVB3cY6h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "train_gen = im_datagen(train_list, train_labels, batch_size = batch_size, shuffle = True)\n",
        "\n",
        "test_gen = im_datagen(test_list, test_labels, batch_size = batch_size, shuffle = False)"
      ],
      "metadata": {
        "id": "mxMglYp_dZas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "x_test.[17]"
      ],
      "metadata": {
        "id": "DnBt86wk4t3z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "y_test[17]"
      ],
      "metadata": {
        "id": "yxN19TlH8P4P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter(y_test).keys() # equals to list(set(words))"
      ],
      "metadata": {
        "id": "COF20gK3xIeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Counter(y_test).values() # counts the elements' frequency"
      ],
      "metadata": {
        "id": "antHWObT3nF0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LeisonSequence(keras.utils.Sequence):\n",
        "\n",
        "    def __init__(self, x_set, y_set, batch_size = 32):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        batch_x = self.x[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "        batch_y = self.y[idx * self.batch_size:(idx + 1) *\n",
        "        self.batch_size]\n",
        "\n",
        "        images = []\n",
        "\n",
        "        for file_name in batch_x:\n",
        "          images.append(cv2.resize(cv2.imread(file_name), (224, 224)))\n",
        "\n",
        "        return (np.array(images)/255), np.array(batch_y)"
      ],
      "metadata": {
        "id": "qLIkj9LCxIhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "test = []\n",
        "\n",
        "for file_name in x_test[0:5]:\n",
        "  test.append(rescale(io.imread(file_name), (0.5, 0.5, 1)))\n",
        "  #print(file_name)\n",
        "\n",
        "test = np.array(test)\n",
        "plt.imshow(test[3])"
      ],
      "metadata": {
        "id": "AWR3pGgIfO_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_img_gen = LeisonSequence(train_list, train_labels, 50)\n",
        "val_img_gen = LeisonSequence(test_list, test_labels, 50)"
      ],
      "metadata": {
        "id": "x-EVrrT2xIl5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model = keras.applications.ResNet50(\n",
        "model = keras.applications.ResNet50(\n",
        "    include_top=True,\n",
        "    weights=None,\n",
        "    input_shape=(224, 224, 3),\n",
        "    classes=7,\n",
        "    pooling=None\n",
        ")"
      ],
      "metadata": {
        "id": "o18kmISZ5Zfz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#base_model.summary()\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1aYNxMbg6RJD",
        "outputId": "886c7673-bd71-4ccb-d708-99170ec30ff1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 224, 224, 3  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)      (None, 230, 230, 3)  0           ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)            (None, 112, 112, 64  9472        ['conv1_pad[0][0]']              \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalization)  (None, 112, 112, 64  256         ['conv1_conv[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)        (None, 112, 112, 64  0           ['conv1_bn[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)      (None, 114, 114, 64  0           ['conv1_relu[0][0]']             \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)      (None, 56, 56, 64)   0           ['pool1_pad[0][0]']              \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2D)   (None, 56, 56, 64)   4160        ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2D)   (None, 56, 56, 256)  16640       ['pool1_pool[0][0]']             \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_0_bn[0][0]',      \n",
            "                                                                  'conv2_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)         (None, 56, 56, 256)  0           ['conv2_block1_out[0][0]',       \n",
            "                                                                  'conv2_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2D)   (None, 56, 56, 64)   16448       ['conv2_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2D)   (None, 56, 56, 64)   36928       ['conv2_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNormal  (None, 56, 56, 64)  256         ['conv2_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activatio  (None, 56, 56, 64)  0           ['conv2_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2D)   (None, 56, 56, 256)  16640       ['conv2_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNormal  (None, 56, 56, 256)  1024       ['conv2_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)         (None, 56, 56, 256)  0           ['conv2_block2_out[0][0]',       \n",
            "                                                                  'conv2_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activation)  (None, 56, 56, 256)  0           ['conv2_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2D)   (None, 28, 28, 128)  32896       ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2D)   (None, 28, 28, 512)  131584      ['conv2_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_0_bn[0][0]',      \n",
            "                                                                  'conv3_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)         (None, 28, 28, 512)  0           ['conv3_block1_out[0][0]',       \n",
            "                                                                  'conv3_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)         (None, 28, 28, 512)  0           ['conv3_block2_out[0][0]',       \n",
            "                                                                  'conv3_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2D)   (None, 28, 28, 128)  65664       ['conv3_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2D)   (None, 28, 28, 128)  147584      ['conv3_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNormal  (None, 28, 28, 128)  512        ['conv3_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activatio  (None, 28, 28, 128)  0          ['conv3_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2D)   (None, 28, 28, 512)  66048       ['conv3_block4_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNormal  (None, 28, 28, 512)  2048       ['conv3_block4_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)         (None, 28, 28, 512)  0           ['conv3_block3_out[0][0]',       \n",
            "                                                                  'conv3_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activation)  (None, 28, 28, 512)  0           ['conv3_block4_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2D)   (None, 14, 14, 256)  131328      ['conv3_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2D)   (None, 14, 14, 1024  525312      ['conv3_block4_out[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block1_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_0_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block1_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_0_bn[0][0]',      \n",
            "                                )                                 'conv4_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block1_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block2_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block2_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)         (None, 14, 14, 1024  0           ['conv4_block1_out[0][0]',       \n",
            "                                )                                 'conv4_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block2_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block3_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block3_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)         (None, 14, 14, 1024  0           ['conv4_block2_out[0][0]',       \n",
            "                                )                                 'conv4_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block3_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block3_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block4_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block4_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block4_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block4_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block4_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)         (None, 14, 14, 1024  0           ['conv4_block3_out[0][0]',       \n",
            "                                )                                 'conv4_block4_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block4_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block4_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block5_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block5_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block5_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block5_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block5_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)         (None, 14, 14, 1024  0           ['conv4_block4_out[0][0]',       \n",
            "                                )                                 'conv4_block5_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block5_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2D)   (None, 14, 14, 256)  262400      ['conv4_block5_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2D)   (None, 14, 14, 256)  590080      ['conv4_block6_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNormal  (None, 14, 14, 256)  1024       ['conv4_block6_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activatio  (None, 14, 14, 256)  0          ['conv4_block6_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_3_conv (Conv2D)   (None, 14, 14, 1024  263168      ['conv4_block6_2_relu[0][0]']    \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_3_bn (BatchNormal  (None, 14, 14, 1024  4096       ['conv4_block6_3_conv[0][0]']    \n",
            " ization)                       )                                                                 \n",
            "                                                                                                  \n",
            " conv4_block6_add (Add)         (None, 14, 14, 1024  0           ['conv4_block5_out[0][0]',       \n",
            "                                )                                 'conv4_block6_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv4_block6_out (Activation)  (None, 14, 14, 1024  0           ['conv4_block6_add[0][0]']       \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv5_block1_1_conv (Conv2D)   (None, 7, 7, 512)    524800      ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block1_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block1_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block1_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block1_0_conv (Conv2D)   (None, 7, 7, 2048)   2099200     ['conv4_block6_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block1_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block1_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block1_0_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_0_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block1_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block1_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_0_bn[0][0]',      \n",
            "                                                                  'conv5_block1_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block1_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block1_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block1_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block2_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block2_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block2_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block2_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block2_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block2_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block2_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block2_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block2_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block1_out[0][0]',       \n",
            "                                                                  'conv5_block2_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block2_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block2_add[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_conv (Conv2D)   (None, 7, 7, 512)    1049088     ['conv5_block2_out[0][0]']       \n",
            "                                                                                                  \n",
            " conv5_block3_1_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_1_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_1_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_1_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_2_conv (Conv2D)   (None, 7, 7, 512)    2359808     ['conv5_block3_1_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_2_bn (BatchNormal  (None, 7, 7, 512)   2048        ['conv5_block3_2_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_2_relu (Activatio  (None, 7, 7, 512)   0           ['conv5_block3_2_bn[0][0]']      \n",
            " n)                                                                                               \n",
            "                                                                                                  \n",
            " conv5_block3_3_conv (Conv2D)   (None, 7, 7, 2048)   1050624     ['conv5_block3_2_relu[0][0]']    \n",
            "                                                                                                  \n",
            " conv5_block3_3_bn (BatchNormal  (None, 7, 7, 2048)  8192        ['conv5_block3_3_conv[0][0]']    \n",
            " ization)                                                                                         \n",
            "                                                                                                  \n",
            " conv5_block3_add (Add)         (None, 7, 7, 2048)   0           ['conv5_block2_out[0][0]',       \n",
            "                                                                  'conv5_block3_3_bn[0][0]']      \n",
            "                                                                                                  \n",
            " conv5_block3_out (Activation)  (None, 7, 7, 2048)   0           ['conv5_block3_add[0][0]']       \n",
            "                                                                                                  \n",
            " avg_pool (GlobalAveragePooling  (None, 2048)        0           ['conv5_block3_out[0][0]']       \n",
            " 2D)                                                                                              \n",
            "                                                                                                  \n",
            " predictions (Dense)            (None, 7)            14343       ['avg_pool[0][0]']               \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 23,602,055\n",
            "Trainable params: 23,548,935\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3))\n",
        "last_layer = base_model.get_layer('global_average_pooling2d')\n",
        "\n",
        "print ('last layer output shape:', last_layer.output_shape)\n",
        "\n",
        "bm_out = last_layer.output\n",
        "#x = base_model(inputs, training=False)\n",
        "x = keras.layers.Dense(128, activation='relu')(bm_out)\n",
        "#x = keras.layers.Dropout(0.5)(x)\n",
        "outputs = keras.layers.Dense(7, activation='softmax')(x)\n",
        "#model = keras.Model(inputs, outputs)\n",
        "model = keras.Model(base_model.input, outputs)"
      ],
      "metadata": {
        "id": "drtS5_zLyPjy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "UvClYg6czAlI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.0002,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.9)\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.0002)\n",
        "adam = keras.optimizers.Adam(learning_rate=lr_schedule, amsgrad=True)\n",
        "nadam = keras.optimizers.Nadam(learning_rate=0.0002)"
      ],
      "metadata": {
        "id": "x8q9amiXYVZA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=nadam ,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "KDeUMEV66RMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/Newcastle University/Machine Learning/Models/resnet50_aug.h5')"
      ],
      "metadata": {
        "id": "yVvfUzC8x35n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cp = keras.callbacks.ModelCheckpoint(filepath = '/content/drive/MyDrive/Newcastle University/Machine Learning/Models/resnet50_aug.h5', verbose = 1, save_best_only = True, monitor='val_accuracy')"
      ],
      "metadata": {
        "id": "XFcQU2BP6RPL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_img_gen, epochs=100, validation_data=val_img_gen, callbacks=cp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_b8WWMNB6RR_",
        "outputId": "fc110d21-22cf-4e8d-828d-6ed2266c711a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.9106 - accuracy: 0.7867 \n",
            "Epoch 00001: val_accuracy improved from -inf to 0.74264, saving model to /content/drive/MyDrive/Newcastle University/Machine Learning/Models/resnet50_aug.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/functional.py:1410: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
            "  layer_config = serialize_layer_fn(layer)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r400/400 [==============================] - 8575s 21s/step - loss: 0.9106 - accuracy: 0.7867 - val_loss: 0.9539 - val_accuracy: 0.7426\n",
            "Epoch 2/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.4874 - accuracy: 0.8277\n",
            "Epoch 00002: val_accuracy improved from 0.74264 to 0.75212, saving model to /content/drive/MyDrive/Newcastle University/Machine Learning/Models/resnet50_aug.h5\n",
            "400/400 [==============================] - 243s 608ms/step - loss: 0.4874 - accuracy: 0.8277 - val_loss: 0.7529 - val_accuracy: 0.7521\n",
            "Epoch 3/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3960 - accuracy: 0.8612\n",
            "Epoch 00003: val_accuracy improved from 0.75212 to 0.76509, saving model to /content/drive/MyDrive/Newcastle University/Machine Learning/Models/resnet50_aug.h5\n",
            "400/400 [==============================] - 243s 608ms/step - loss: 0.3960 - accuracy: 0.8612 - val_loss: 0.7264 - val_accuracy: 0.7651\n",
            "Epoch 4/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.3119 - accuracy: 0.8942\n",
            "Epoch 00004: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 0.3119 - accuracy: 0.8942 - val_loss: 0.7934 - val_accuracy: 0.7571\n",
            "Epoch 5/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.2102 - accuracy: 0.9363\n",
            "Epoch 00005: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 0.2102 - accuracy: 0.9363 - val_loss: 0.9461 - val_accuracy: 0.7561\n",
            "Epoch 6/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.1046 - accuracy: 0.9752\n",
            "Epoch 00006: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 237s 592ms/step - loss: 0.1046 - accuracy: 0.9752 - val_loss: 1.1197 - val_accuracy: 0.7481\n",
            "Epoch 7/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9958\n",
            "Epoch 00007: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 595ms/step - loss: 0.0332 - accuracy: 0.9958 - val_loss: 1.3036 - val_accuracy: 0.7491\n",
            "Epoch 8/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9998\n",
            "Epoch 00008: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 594ms/step - loss: 0.0091 - accuracy: 0.9998 - val_loss: 1.4741 - val_accuracy: 0.7491\n",
            "Epoch 9/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 1.0000\n",
            "Epoch 00009: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 1.5834 - val_accuracy: 0.7496\n",
            "Epoch 10/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0023 - accuracy: 1.0000\n",
            "Epoch 00010: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 596ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 1.6679 - val_accuracy: 0.7506\n",
            "Epoch 11/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0015 - accuracy: 1.0000\n",
            "Epoch 00011: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.7222 - val_accuracy: 0.7486\n",
            "Epoch 12/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 0.0010 - accuracy: 1.0000\n",
            "Epoch 00012: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.8002 - val_accuracy: 0.7506\n",
            "Epoch 13/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.1622e-04 - accuracy: 1.0000\n",
            "Epoch 00013: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 7.1622e-04 - accuracy: 1.0000 - val_loss: 1.8528 - val_accuracy: 0.7481\n",
            "Epoch 14/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.2065e-04 - accuracy: 1.0000\n",
            "Epoch 00014: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 596ms/step - loss: 5.2065e-04 - accuracy: 1.0000 - val_loss: 1.9050 - val_accuracy: 0.7506\n",
            "Epoch 15/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.8556e-04 - accuracy: 1.0000\n",
            "Epoch 00015: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 594ms/step - loss: 3.8556e-04 - accuracy: 1.0000 - val_loss: 1.9525 - val_accuracy: 0.7486\n",
            "Epoch 16/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.8897e-04 - accuracy: 1.0000\n",
            "Epoch 00016: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.8897e-04 - accuracy: 1.0000 - val_loss: 1.9959 - val_accuracy: 0.7471\n",
            "Epoch 17/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.1861e-04 - accuracy: 1.0000\n",
            "Epoch 00017: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.1861e-04 - accuracy: 1.0000 - val_loss: 2.0456 - val_accuracy: 0.7516\n",
            "Epoch 18/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.6681e-04 - accuracy: 1.0000\n",
            "Epoch 00018: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.6681e-04 - accuracy: 1.0000 - val_loss: 2.0892 - val_accuracy: 0.7486\n",
            "Epoch 19/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.2833e-04 - accuracy: 1.0000\n",
            "Epoch 00019: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 596ms/step - loss: 1.2833e-04 - accuracy: 1.0000 - val_loss: 2.1337 - val_accuracy: 0.7506\n",
            "Epoch 20/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 9.9077e-05 - accuracy: 1.0000\n",
            "Epoch 00020: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 9.9077e-05 - accuracy: 1.0000 - val_loss: 2.1708 - val_accuracy: 0.7486\n",
            "Epoch 21/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.6852e-05 - accuracy: 1.0000\n",
            "Epoch 00021: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 7.6852e-05 - accuracy: 1.0000 - val_loss: 2.2180 - val_accuracy: 0.7471\n",
            "Epoch 22/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.9846e-05 - accuracy: 1.0000\n",
            "Epoch 00022: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 5.9846e-05 - accuracy: 1.0000 - val_loss: 2.2623 - val_accuracy: 0.7481\n",
            "Epoch 23/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.6811e-05 - accuracy: 1.0000\n",
            "Epoch 00023: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 4.6811e-05 - accuracy: 1.0000 - val_loss: 2.2946 - val_accuracy: 0.7486\n",
            "Epoch 24/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.6716e-05 - accuracy: 1.0000\n",
            "Epoch 00024: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 601ms/step - loss: 3.6716e-05 - accuracy: 1.0000 - val_loss: 2.3398 - val_accuracy: 0.7466\n",
            "Epoch 25/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.8869e-05 - accuracy: 1.0000\n",
            "Epoch 00025: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 601ms/step - loss: 2.8869e-05 - accuracy: 1.0000 - val_loss: 2.3665 - val_accuracy: 0.7451\n",
            "Epoch 26/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.2768e-05 - accuracy: 1.0000\n",
            "Epoch 00026: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.2768e-05 - accuracy: 1.0000 - val_loss: 2.4134 - val_accuracy: 0.7466\n",
            "Epoch 27/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.7989e-05 - accuracy: 1.0000\n",
            "Epoch 00027: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 595ms/step - loss: 1.7989e-05 - accuracy: 1.0000 - val_loss: 2.4358 - val_accuracy: 0.7461\n",
            "Epoch 28/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.4264e-05 - accuracy: 1.0000\n",
            "Epoch 00028: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 1.4264e-05 - accuracy: 1.0000 - val_loss: 2.4807 - val_accuracy: 0.7486\n",
            "Epoch 29/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.1327e-05 - accuracy: 1.0000\n",
            "Epoch 00029: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 1.1327e-05 - accuracy: 1.0000 - val_loss: 2.5230 - val_accuracy: 0.7461\n",
            "Epoch 30/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 9.0138e-06 - accuracy: 1.0000\n",
            "Epoch 00030: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 9.0138e-06 - accuracy: 1.0000 - val_loss: 2.5524 - val_accuracy: 0.7461\n",
            "Epoch 31/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.1910e-06 - accuracy: 1.0000\n",
            "Epoch 00031: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 7.1910e-06 - accuracy: 1.0000 - val_loss: 2.5705 - val_accuracy: 0.7481\n",
            "Epoch 32/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.7560e-06 - accuracy: 1.0000\n",
            "Epoch 00032: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 5.7560e-06 - accuracy: 1.0000 - val_loss: 2.6103 - val_accuracy: 0.7461\n",
            "Epoch 33/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.6206e-06 - accuracy: 1.0000\n",
            "Epoch 00033: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 596ms/step - loss: 4.6206e-06 - accuracy: 1.0000 - val_loss: 2.6464 - val_accuracy: 0.7431\n",
            "Epoch 34/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.7244e-06 - accuracy: 1.0000\n",
            "Epoch 00034: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 3.7244e-06 - accuracy: 1.0000 - val_loss: 2.6751 - val_accuracy: 0.7441\n",
            "Epoch 35/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0044e-06 - accuracy: 1.0000\n",
            "Epoch 00035: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 3.0044e-06 - accuracy: 1.0000 - val_loss: 2.7031 - val_accuracy: 0.7416\n",
            "Epoch 36/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.4333e-06 - accuracy: 1.0000\n",
            "Epoch 00036: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 2.4333e-06 - accuracy: 1.0000 - val_loss: 2.7466 - val_accuracy: 0.7421\n",
            "Epoch 37/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.9774e-06 - accuracy: 1.0000\n",
            "Epoch 00037: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 1.9774e-06 - accuracy: 1.0000 - val_loss: 2.7589 - val_accuracy: 0.7451\n",
            "Epoch 38/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.6132e-06 - accuracy: 1.0000\n",
            "Epoch 00038: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 1.6132e-06 - accuracy: 1.0000 - val_loss: 2.7895 - val_accuracy: 0.7441\n",
            "Epoch 39/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.3207e-06 - accuracy: 1.0000\n",
            "Epoch 00039: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.3207e-06 - accuracy: 1.0000 - val_loss: 2.8146 - val_accuracy: 0.7416\n",
            "Epoch 40/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.0865e-06 - accuracy: 1.0000\n",
            "Epoch 00040: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 1.0865e-06 - accuracy: 1.0000 - val_loss: 2.8431 - val_accuracy: 0.7426\n",
            "Epoch 41/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 8.9562e-07 - accuracy: 1.0000\n",
            "Epoch 00041: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 8.9562e-07 - accuracy: 1.0000 - val_loss: 2.8591 - val_accuracy: 0.7411\n",
            "Epoch 42/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.4257e-07 - accuracy: 1.0000\n",
            "Epoch 00042: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 7.4257e-07 - accuracy: 1.0000 - val_loss: 2.8848 - val_accuracy: 0.7431\n",
            "Epoch 43/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 6.1750e-07 - accuracy: 1.0000\n",
            "Epoch 00043: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 6.1750e-07 - accuracy: 1.0000 - val_loss: 2.9112 - val_accuracy: 0.7431\n",
            "Epoch 44/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.1540e-07 - accuracy: 1.0000\n",
            "Epoch 00044: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 238s 596ms/step - loss: 5.1540e-07 - accuracy: 1.0000 - val_loss: 2.9234 - val_accuracy: 0.7421\n",
            "Epoch 45/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.3240e-07 - accuracy: 1.0000\n",
            "Epoch 00045: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 4.3240e-07 - accuracy: 1.0000 - val_loss: 2.9576 - val_accuracy: 0.7436\n",
            "Epoch 46/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.6445e-07 - accuracy: 1.0000\n",
            "Epoch 00046: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 3.6445e-07 - accuracy: 1.0000 - val_loss: 2.9735 - val_accuracy: 0.7416\n",
            "Epoch 47/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.0800e-07 - accuracy: 1.0000\n",
            "Epoch 00047: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 3.0800e-07 - accuracy: 1.0000 - val_loss: 2.9851 - val_accuracy: 0.7446\n",
            "Epoch 48/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.6186e-07 - accuracy: 1.0000\n",
            "Epoch 00048: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 2.6186e-07 - accuracy: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.7436\n",
            "Epoch 49/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.2328e-07 - accuracy: 1.0000\n",
            "Epoch 00049: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.2328e-07 - accuracy: 1.0000 - val_loss: 3.0309 - val_accuracy: 0.7436\n",
            "Epoch 50/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.9073e-07 - accuracy: 1.0000\n",
            "Epoch 00050: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 1.9073e-07 - accuracy: 1.0000 - val_loss: 3.0277 - val_accuracy: 0.7401\n",
            "Epoch 51/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.6413e-07 - accuracy: 1.0000\n",
            "Epoch 00051: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 596ms/step - loss: 1.6413e-07 - accuracy: 1.0000 - val_loss: 3.0424 - val_accuracy: 0.7421\n",
            "Epoch 52/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.4173e-07 - accuracy: 1.0000\n",
            "Epoch 00052: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 1.4173e-07 - accuracy: 1.0000 - val_loss: 3.0622 - val_accuracy: 0.7411\n",
            "Epoch 53/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.2207e-07 - accuracy: 1.0000\n",
            "Epoch 00053: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.2207e-07 - accuracy: 1.0000 - val_loss: 3.0894 - val_accuracy: 0.7426\n",
            "Epoch 54/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.0620e-07 - accuracy: 1.0000\n",
            "Epoch 00054: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.0620e-07 - accuracy: 1.0000 - val_loss: 3.0789 - val_accuracy: 0.7406\n",
            "Epoch 55/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 9.2340e-08 - accuracy: 1.0000\n",
            "Epoch 00055: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 9.2340e-08 - accuracy: 1.0000 - val_loss: 3.1038 - val_accuracy: 0.7397\n",
            "Epoch 56/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 8.1003e-08 - accuracy: 1.0000\n",
            "Epoch 00056: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 8.1003e-08 - accuracy: 1.0000 - val_loss: 3.1021 - val_accuracy: 0.7411\n",
            "Epoch 57/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.0834e-08 - accuracy: 1.0000\n",
            "Epoch 00057: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 7.0834e-08 - accuracy: 1.0000 - val_loss: 3.1197 - val_accuracy: 0.7416\n",
            "Epoch 58/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 6.2305e-08 - accuracy: 1.0000\n",
            "Epoch 00058: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 6.2305e-08 - accuracy: 1.0000 - val_loss: 3.1327 - val_accuracy: 0.7411\n",
            "Epoch 59/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.4860e-08 - accuracy: 1.0000\n",
            "Epoch 00059: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 5.4860e-08 - accuracy: 1.0000 - val_loss: 3.1408 - val_accuracy: 0.7406\n",
            "Epoch 60/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.8065e-08 - accuracy: 1.0000\n",
            "Epoch 00060: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 4.8065e-08 - accuracy: 1.0000 - val_loss: 3.1413 - val_accuracy: 0.7392\n",
            "Epoch 61/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.2427e-08 - accuracy: 1.0000\n",
            "Epoch 00061: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 4.2427e-08 - accuracy: 1.0000 - val_loss: 3.1515 - val_accuracy: 0.7421\n",
            "Epoch 62/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.7020e-08 - accuracy: 1.0000\n",
            "Epoch 00062: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 3.7020e-08 - accuracy: 1.0000 - val_loss: 3.1672 - val_accuracy: 0.7406\n",
            "Epoch 63/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.2175e-08 - accuracy: 1.0000\n",
            "Epoch 00063: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 3.2175e-08 - accuracy: 1.0000 - val_loss: 3.1737 - val_accuracy: 0.7416\n",
            "Epoch 64/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.7877e-08 - accuracy: 1.0000\n",
            "Epoch 00064: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.7877e-08 - accuracy: 1.0000 - val_loss: 3.1855 - val_accuracy: 0.7411\n",
            "Epoch 65/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.4104e-08 - accuracy: 1.0000\n",
            "Epoch 00065: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 596ms/step - loss: 2.4104e-08 - accuracy: 1.0000 - val_loss: 3.1973 - val_accuracy: 0.7421\n",
            "Epoch 66/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.0814e-08 - accuracy: 1.0000\n",
            "Epoch 00066: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 596ms/step - loss: 2.0814e-08 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.7411\n",
            "Epoch 67/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.8293e-08 - accuracy: 1.0000\n",
            "Epoch 00067: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 1.8293e-08 - accuracy: 1.0000 - val_loss: 3.2011 - val_accuracy: 0.7411\n",
            "Epoch 68/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.5867e-08 - accuracy: 1.0000\n",
            "Epoch 00068: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 1.5867e-08 - accuracy: 1.0000 - val_loss: 3.1996 - val_accuracy: 0.7426\n",
            "Epoch 69/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.3793e-08 - accuracy: 1.0000\n",
            "Epoch 00069: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 1.3793e-08 - accuracy: 1.0000 - val_loss: 3.2217 - val_accuracy: 0.7426\n",
            "Epoch 70/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.1897e-08 - accuracy: 1.0000\n",
            "Epoch 00070: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.1897e-08 - accuracy: 1.0000 - val_loss: 3.2125 - val_accuracy: 0.7416\n",
            "Epoch 71/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 1.0455e-08 - accuracy: 1.0000\n",
            "Epoch 00071: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 1.0455e-08 - accuracy: 1.0000 - val_loss: 3.2156 - val_accuracy: 0.7401\n",
            "Epoch 72/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 9.2506e-09 - accuracy: 1.0000\n",
            "Epoch 00072: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 9.2506e-09 - accuracy: 1.0000 - val_loss: 3.2162 - val_accuracy: 0.7372\n",
            "Epoch 73/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 8.4400e-09 - accuracy: 1.0000\n",
            "Epoch 00073: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 8.4400e-09 - accuracy: 1.0000 - val_loss: 3.2207 - val_accuracy: 0.7377\n",
            "Epoch 74/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 7.6890e-09 - accuracy: 1.0000\n",
            "Epoch 00074: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 7.6890e-09 - accuracy: 1.0000 - val_loss: 3.2405 - val_accuracy: 0.7416\n",
            "Epoch 75/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 6.8307e-09 - accuracy: 1.0000\n",
            "Epoch 00075: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 6.8307e-09 - accuracy: 1.0000 - val_loss: 3.2365 - val_accuracy: 0.7406\n",
            "Epoch 76/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 6.4015e-09 - accuracy: 1.0000\n",
            "Epoch 00076: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 241s 601ms/step - loss: 6.4015e-09 - accuracy: 1.0000 - val_loss: 3.2491 - val_accuracy: 0.7416\n",
            "Epoch 77/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.9664e-09 - accuracy: 1.0000\n",
            "Epoch 00077: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 5.9664e-09 - accuracy: 1.0000 - val_loss: 3.2460 - val_accuracy: 0.7382\n",
            "Epoch 78/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.6803e-09 - accuracy: 1.0000\n",
            "Epoch 00078: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 5.6803e-09 - accuracy: 1.0000 - val_loss: 3.2555 - val_accuracy: 0.7397\n",
            "Epoch 79/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 5.0843e-09 - accuracy: 1.0000\n",
            "Epoch 00079: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 241s 602ms/step - loss: 5.0843e-09 - accuracy: 1.0000 - val_loss: 3.2528 - val_accuracy: 0.7392\n",
            "Epoch 80/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.6790e-09 - accuracy: 1.0000\n",
            "Epoch 00080: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 601ms/step - loss: 4.6790e-09 - accuracy: 1.0000 - val_loss: 3.2548 - val_accuracy: 0.7392\n",
            "Epoch 81/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.6492e-09 - accuracy: 1.0000\n",
            "Epoch 00081: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 4.6492e-09 - accuracy: 1.0000 - val_loss: 3.2888 - val_accuracy: 0.7441\n",
            "Epoch 82/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 4.3869e-09 - accuracy: 1.0000\n",
            "Epoch 00082: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 601ms/step - loss: 4.3869e-09 - accuracy: 1.0000 - val_loss: 3.3031 - val_accuracy: 0.7392\n",
            "Epoch 83/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.8803e-09 - accuracy: 1.0000\n",
            "Epoch 00083: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 3.8803e-09 - accuracy: 1.0000 - val_loss: 3.2904 - val_accuracy: 0.7436\n",
            "Epoch 84/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.9101e-09 - accuracy: 1.0000\n",
            "Epoch 00084: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 3.9101e-09 - accuracy: 1.0000 - val_loss: 3.2790 - val_accuracy: 0.7411\n",
            "Epoch 85/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.4332e-09 - accuracy: 1.0000\n",
            "Epoch 00085: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 3.4332e-09 - accuracy: 1.0000 - val_loss: 3.2953 - val_accuracy: 0.7397\n",
            "Epoch 86/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.3796e-09 - accuracy: 1.0000\n",
            "Epoch 00086: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 3.3796e-09 - accuracy: 1.0000 - val_loss: 3.3008 - val_accuracy: 0.7401\n",
            "Epoch 87/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 3.3200e-09 - accuracy: 1.0000\n",
            "Epoch 00087: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 597ms/step - loss: 3.3200e-09 - accuracy: 1.0000 - val_loss: 3.2908 - val_accuracy: 0.7401\n",
            "Epoch 88/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.8372e-09 - accuracy: 1.0000\n",
            "Epoch 00088: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.8372e-09 - accuracy: 1.0000 - val_loss: 3.2943 - val_accuracy: 0.7401\n",
            "Epoch 89/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.8431e-09 - accuracy: 1.0000\n",
            "Epoch 00089: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 601ms/step - loss: 2.8431e-09 - accuracy: 1.0000 - val_loss: 3.3024 - val_accuracy: 0.7431\n",
            "Epoch 90/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.7299e-09 - accuracy: 1.0000\n",
            "Epoch 00090: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.7299e-09 - accuracy: 1.0000 - val_loss: 3.2968 - val_accuracy: 0.7387\n",
            "Epoch 91/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.5272e-09 - accuracy: 1.0000\n",
            "Epoch 00091: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 239s 598ms/step - loss: 2.5272e-09 - accuracy: 1.0000 - val_loss: 3.3006 - val_accuracy: 0.7406\n",
            "Epoch 92/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.3603e-09 - accuracy: 1.0000\n",
            "Epoch 00092: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 599ms/step - loss: 2.3603e-09 - accuracy: 1.0000 - val_loss: 3.2958 - val_accuracy: 0.7397\n",
            "Epoch 93/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.3544e-09 - accuracy: 1.0000\n",
            "Epoch 00093: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 2.3544e-09 - accuracy: 1.0000 - val_loss: 3.2989 - val_accuracy: 0.7397\n",
            "Epoch 94/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.2829e-09 - accuracy: 1.0000\n",
            "Epoch 00094: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 240s 600ms/step - loss: 2.2829e-09 - accuracy: 1.0000 - val_loss: 3.3084 - val_accuracy: 0.7382\n",
            "Epoch 95/100\n",
            "400/400 [==============================] - ETA: 0s - loss: 2.1636e-09 - accuracy: 1.0000\n",
            "Epoch 00095: val_accuracy did not improve from 0.76509\n",
            "400/400 [==============================] - 241s 601ms/step - loss: 2.1636e-09 - accuracy: 1.0000 - val_loss: 3.3120 - val_accuracy: 0.7426\n",
            "Epoch 96/100\n",
            "326/400 [=======================>......] - ETA: 38s - loss: 1.8064e-09 - accuracy: 1.0000"
          ]
        }
      ]
    }
  ]
}